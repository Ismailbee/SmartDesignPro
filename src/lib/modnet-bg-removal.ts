/**
 * RMBG-1.4 Background Removal - State-of-the-Art ONNX Runtime Implementation
 *
 * This module provides professional-grade background removal using BRIA AI's RMBG-1.4 model
 * with ONNX Runtime WebGPU/WASM execution providers.
 *
 * Features:
 * - State-of-the-art RMBG-1.4 model (95-99% foreground preservation)
 * - WebGPU acceleration (fallback to WASM)
 * - Model caching in IndexedDB (instant subsequent loads)
 * - Download progress tracking
 * - Session reuse and warm-up
 * - Configurable model parameters
 * - Server fallback for unsupported devices
 * - Preserves fine details (hair, edges, fingers)
 *
 * @module modnet-bg-removal
 */

import type * as ORT from 'onnxruntime-web'

// ============================================================================
// CONFIGURATION
// ============================================================================

/**
 * Model configuration - Update these based on your ONNX model
 */
export const CONFIG = {
  // Model URL - Using RMBG-1.4 Quantized for best compatibility
  // RMBG-1.4 is state-of-the-art background removal (better than MODNet)
  // Note: FP16 model requires WebGPU f16 extension (not widely supported yet)
  MODEL_URL: 'https://huggingface.co/briaai/RMBG-1.4/resolve/main/onnx/model_quantized.onnx',

  // Alternative URLs (fallback order) - RMBG-1.4 variants
  FALLBACK_MODEL_URLS: [
    'https://huggingface.co/briaai/RMBG-1.4/resolve/main/onnx/model_quantized.onnx', // 44MB - BEST COMPATIBILITY ‚úÖ
    'https://huggingface.co/briaai/RMBG-1.4/resolve/main/onnx/model.onnx',           // 176MB - Full precision (WASM only)
    'https://huggingface.co/briaai/RMBG-1.4/resolve/main/onnx/model_fp16.onnx',      // 88MB - Requires f16 extension
  ],

  // Model caching options
  ENABLE_MODEL_CACHE: true,                 // Cache model in IndexedDB for instant loading
  CACHE_NAME: 'rmbg-model-cache',           // IndexedDB database name
  MODEL_CACHE_KEY: 'rmbg-1.4-quantized-v1', // Cache key (change to invalidate cache)

  // Loading timeout
  MODEL_LOAD_TIMEOUT: 90000,             // 90 seconds timeout for model loading (larger model)

  // Input/output tensor names (auto-detected if not specified)
  INPUT_NAME: 'input',
  OUTPUT_NAME: 'output',

  // Model input size - RMBG-1.4 uses 1024x1024 for best quality
  // Can be reduced to 512 or 768 for faster processing with slight quality loss
  INPUT_SIZE: 1024, // RMBG-1.4 optimal size (can reduce to 512 for speed)

  // Normalization parameters for RMBG-1.4
  // RMBG-1.4 uses [0.5, 0.5, 0.5] for both mean and std
  MEAN: [0.5, 0.5, 0.5], // RMBG-1.4 normalization
  STD: [1.0, 1.0, 1.0],  // RMBG-1.4 normalization (divide by 1.0 = no scaling)

  // Alpha mask processing options
  ENABLE_SMOOTHING: true,      // Enable edge smoothing (Gaussian blur)
  ENABLE_ENHANCEMENT: false,   // Disable aggressive enhancement to preserve foreground
  SMOOTHING_RADIUS: 1,         // Gaussian blur radius (1 = subtle smoothing)

  // Debug options
  DEBUG_LOGGING: true,         // Enable detailed console logging for diagnostics
  LOG_ALPHA_STATS: true,       // Log alpha mask statistics (min/max/avg values)

  // Server fallback endpoint
  SERVER_ENDPOINT: '/api/remove-bg',

  // Performance options
  ENABLE_WARMUP: false, // Disabled for faster first load
  REUSE_SESSION: true,

  // Execution provider preference order
  // Using WASM only for better compatibility (WebGPU f16 extension not widely supported)
  // Change to ['webgpu', 'wasm'] if your browser supports WebGPU f16 extension
  EXECUTION_PROVIDERS: ['wasm'] as const,
}

// ============================================================================
// TYPES
// ============================================================================

export interface RemoveBackgroundOptions {
  /** Use server fallback if local runtime fails */
  useServerFallback?: boolean
  
  /** Quality/speed tradeoff */
  quality?: 'fast' | 'balanced' | 'high'
  
  /** Output format */
  outputFormat?: 'image/png' | 'image/webp'
  
  /** Progress callback */
  onProgress?: (progress: number, stage: string) => void
}

export interface RemoveBackgroundResult {
  /** Output image blob with alpha channel */
  blob: Blob

  /** Data URL of the result */
  dataUrl: string

  /** Processing time in milliseconds */
  processingTime: number

  /** Execution provider used */
  executionProvider: 'webgpu' | 'wasm' | 'server' | 'imgly'
  
  /** Original image dimensions */
  width: number
  height: number
}

// ============================================================================
// MODEL CACHING (IndexedDB)
// ============================================================================

/**
 * Open IndexedDB for model caching
 */
async function openModelCache(): Promise<IDBDatabase> {
  return new Promise((resolve, reject) => {
    const request = indexedDB.open(CONFIG.CACHE_NAME, 1)

    request.onerror = () => reject(request.error)
    request.onsuccess = () => resolve(request.result)

    request.onupgradeneeded = (event) => {
      const db = (event.target as IDBOpenDBRequest).result
      if (!db.objectStoreNames.contains('models')) {
        db.createObjectStore('models')
      }
    }
  })
}

/**
 * Get cached model from IndexedDB
 */
async function getCachedModel(key: string): Promise<ArrayBuffer | null> {
  if (!CONFIG.ENABLE_MODEL_CACHE) return null

  try {
    const db = await openModelCache()
    return new Promise((resolve, reject) => {
      const transaction = db.transaction(['models'], 'readonly')
      const store = transaction.objectStore('models')
      const request = store.get(key)

      request.onsuccess = () => {
        const result = request.result
        db.close()
        resolve(result || null)
      }
      request.onerror = () => {
        db.close()
        reject(request.error)
      }
    })
  } catch (error) {
    console.warn('Failed to get cached model:', error)
    return null
  }
}

/**
 * Save model to IndexedDB cache
 */
async function cacheModel(key: string, data: ArrayBuffer): Promise<void> {
  if (!CONFIG.ENABLE_MODEL_CACHE) return

  try {
    const db = await openModelCache()
    return new Promise((resolve, reject) => {
      const transaction = db.transaction(['models'], 'readwrite')
      const store = transaction.objectStore('models')
      const request = store.put(data, key)

      request.onsuccess = () => {
        db.close()
        console.log(`‚úÖ Model cached successfully (${(data.byteLength / 1024 / 1024).toFixed(2)} MB)`)
        resolve()
      }
      request.onerror = () => {
        db.close()
        reject(request.error)
      }
    })
  } catch (error) {
    console.warn('Failed to cache model:', error)
  }
}

/**
 * Download model with progress tracking
 */
async function downloadModelWithProgress(
  url: string,
  onProgress?: (progress: number, stage: string) => void
): Promise<ArrayBuffer> {
  console.log(`üì• Downloading model from: ${url}`)

  const response = await fetch(url)
  if (!response.ok) {
    throw new Error(`HTTP ${response.status}: ${response.statusText}`)
  }

  const contentLength = response.headers.get('content-length')
  const total = contentLength ? parseInt(contentLength, 10) : 0

  if (!response.body) {
    throw new Error('Response body is null')
  }

  const reader = response.body.getReader()
  const chunks: Uint8Array[] = []
  let receivedLength = 0

  while (true) {
    const { done, value } = await reader.read()

    if (done) break

    chunks.push(value)
    receivedLength += value.length

    if (total > 0 && onProgress) {
      const progress = Math.round((receivedLength / total) * 100)
      const mbReceived = (receivedLength / 1024 / 1024).toFixed(1)
      const mbTotal = (total / 1024 / 1024).toFixed(1)
      onProgress(progress, `Downloading model: ${mbReceived}/${mbTotal} MB`)
      console.log(`üì• Download progress: ${progress}% (${mbReceived}/${mbTotal} MB)`)
    }
  }

  // Combine chunks into single ArrayBuffer
  const allChunks = new Uint8Array(receivedLength)
  let position = 0
  for (const chunk of chunks) {
    allChunks.set(chunk, position)
    position += chunk.length
  }

  console.log(`‚úÖ Model downloaded successfully (${(receivedLength / 1024 / 1024).toFixed(2)} MB)`)
  return allChunks.buffer
}

// ============================================================================
// GLOBAL STATE
// ============================================================================

let ortInstance: typeof ORT | null = null
let inferenceSession: ORT.InferenceSession | null = null
let isInitialized = false
let initializationPromise: Promise<void> | null = null

// Canvas pool for reuse
const canvasPool: HTMLCanvasElement[] = []

// ============================================================================
// INITIALIZATION
// ============================================================================

/**
 * Lazy-load ONNX Runtime Web
 */
async function loadONNXRuntime(): Promise<typeof ORT> {
  if (ortInstance) return ortInstance

  try {
    ortInstance = await import('onnxruntime-web')

    // Configure ONNX Runtime WASM paths
    // Use CDN for reliable WASM file loading
    ortInstance.env.wasm.wasmPaths = 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.21.0/dist/'

    // Configure ONNX Runtime settings for optimal performance
    // Note: Multi-threading requires cross-origin isolation (not available in most environments)
    // Using single-threaded mode for compatibility
    ortInstance.env.wasm.numThreads = 1 // Single-threaded (multi-threading requires crossOriginIsolated)
    ortInstance.env.wasm.simd = true // Enable SIMD for faster processing
    ortInstance.env.logLevel = 'warning'

    // Disable proxy mode (not needed for single-threaded execution)
    ortInstance.env.wasm.proxy = false

    console.log('‚úÖ ONNX Runtime loaded successfully')
    console.log('üì¶ WASM paths configured:', ortInstance.env.wasm.wasmPaths)
    console.log('üîß Threading mode: Single-threaded (for compatibility)')
    return ortInstance
  } catch (error) {
    console.error('‚ùå Failed to load ONNX Runtime:', error)
    throw new Error('ONNX Runtime not available')
  }
}

/**
 * Detect WebGPU availability
 */
function isWebGPUAvailable(): boolean {
  return typeof navigator !== 'undefined' && 'gpu' in navigator
}

/**
 * Load model with caching and progress tracking
 */
async function loadModelWithFallback(
  ort: typeof ORT,
  provider: string,
  onProgress?: (progress: number, stage: string) => void
): Promise<ORT.InferenceSession> {
  const modelUrls = CONFIG.FALLBACK_MODEL_URLS
  const errors: string[] = []

  // Try to load from cache first
  if (CONFIG.ENABLE_MODEL_CACHE) {
    try {
      console.log('üîç Checking for cached model...')
      onProgress?.(5, 'Checking cache')

      const cachedData = await getCachedModel(CONFIG.MODEL_CACHE_KEY)
      if (cachedData) {
        console.log('‚úÖ Found cached model! Loading from cache...')
        onProgress?.(20, 'Loading from cache')

        const session = await ort.InferenceSession.create(cachedData, {
          executionProviders: [provider],
          graphOptimizationLevel: 'all',
          enableCpuMemArena: true,
          enableMemPattern: true,
        })

        console.log('‚úÖ Model loaded from cache successfully!')
        onProgress?.(100, 'Model loaded from cache')
        return session
      } else {
        console.log('‚ÑπÔ∏è  No cached model found, will download...')
      }
    } catch (error) {
      console.warn('‚ö†Ô∏è  Failed to load from cache:', error)
    }
  }

  // Download and cache model
  for (let i = 0; i < modelUrls.length; i++) {
    const url = modelUrls[i]
    try {
      console.log(`üîÑ Trying to load model from: ${url} (${i + 1}/${modelUrls.length})`)
      onProgress?.(10, `Attempting source ${i + 1}/${modelUrls.length}`)

      // Download with progress tracking
      const modelData = await Promise.race([
        downloadModelWithProgress(url, (progress, stage) => {
          // Map download progress to 10-80% range
          const mappedProgress = 10 + Math.round(progress * 0.7)
          onProgress?.(mappedProgress, stage)
        }),
        new Promise<never>((_, reject) =>
          setTimeout(() => reject(new Error('Download timeout')), CONFIG.MODEL_LOAD_TIMEOUT)
        ),
      ])

      onProgress?.(85, 'Creating inference session')

      // Create session from downloaded data
      const session = await ort.InferenceSession.create(modelData, {
        executionProviders: [provider],
        graphOptimizationLevel: 'all',
        enableCpuMemArena: true,
        enableMemPattern: true,
      })

      console.log(`‚úÖ Successfully loaded model from: ${url}`)

      // Cache the model for future use
      onProgress?.(95, 'Caching model')
      await cacheModel(CONFIG.MODEL_CACHE_KEY, modelData)

      onProgress?.(100, 'Model ready')
      return session
    } catch (error: any) {
      const errorMsg = error?.message || String(error)
      errors.push(`${url}: ${errorMsg}`)
      console.warn(`‚ö†Ô∏è  Failed to load from ${url}:`, errorMsg)

      // If this was a timeout, try next URL
      if (errorMsg.includes('timeout')) {
        console.log('‚è±Ô∏è  Download timed out, trying next source...')
      }
    }
  }

  throw new Error(`Failed to load model from any URL:\n${errors.join('\n')}`)
}

/**
 * Create inference session with best available execution provider
 */
async function createSession(
  ort: typeof ORT,
  onProgress?: (progress: number, stage: string) => void
): Promise<ORT.InferenceSession> {
  const webgpuAvailable = isWebGPUAvailable()

  console.log('üîç WebGPU available:', webgpuAvailable)
  console.log('üì• Primary model URL:', CONFIG.MODEL_URL)

  const errors: Array<{ provider: string; error: any }> = []

  // Try execution providers in order of preference
  for (const provider of CONFIG.EXECUTION_PROVIDERS) {
    // Skip WebGPU if not available (only relevant if WebGPU is in the list)
    if (provider === 'webgpu' && !webgpuAvailable) {
      console.log('‚è≠Ô∏è  Skipping WebGPU (not available)')
      continue
    }

    try {
      console.log(`üîÑ Attempting to create session with ${provider}...`)

      const session = await loadModelWithFallback(ort, provider, onProgress)

      console.log(`‚úÖ Session created successfully with ${provider}`)
      console.log('üìã Input names:', session.inputNames)
      console.log('üìã Output names:', session.outputNames)

      return session
    } catch (error: any) {
      console.warn(`‚ö†Ô∏è  Failed with ${provider}:`, error?.message || error)
      errors.push({ provider, error })
    }
  }

  // All providers failed
  console.error('‚ùå All execution providers failed:')
  errors.forEach(({ provider, error }) => {
    console.error(`   ${provider}:`, error?.message || error)
  })

  throw new Error(
    `Failed to create inference session with any provider. ` +
    `Tried: ${errors.map(e => e.provider).join(', ')}. ` +
    `Check browser console for detailed error messages.`
  )
}

/**
 * Initialize the background removal system
 */
async function initialize(onProgress?: (progress: number, stage: string) => void): Promise<void> {
  if (isInitialized && ortInstance && inferenceSession) return
  if (initializationPromise) return initializationPromise

  initializationPromise = (async () => {
    try {
      console.log('üöÄ Initializing RMBG-1.4 background removal...')
      onProgress?.(5, 'Initializing AI model')

      // Load ONNX Runtime
      const ort = await loadONNXRuntime()

      // Create inference session (this will handle caching and progress)
      const session = await createSession(ort, onProgress)

      if (CONFIG.REUSE_SESSION) {
        inferenceSession = session
      }

      // Warm-up: run a dummy inference
      if (CONFIG.ENABLE_WARMUP) {
        console.log('üî• Warming up model...')
        const dummyInput = new ort.Tensor(
          'float32',
          new Float32Array(3 * CONFIG.INPUT_SIZE * CONFIG.INPUT_SIZE),
          [1, 3, CONFIG.INPUT_SIZE, CONFIG.INPUT_SIZE]
        )

        const inputName = session.inputNames[0] || CONFIG.INPUT_NAME
        await session.run({ [inputName]: dummyInput })

        console.log('‚úÖ Warm-up complete')
      }

      isInitialized = true
      console.log('‚úÖ RMBG-1.4 initialization complete')
    } catch (error) {
      console.error('‚ùå Initialization failed:', error)
      initializationPromise = null
      isInitialized = false
      throw error
    }
  })()

  return initializationPromise
}

// ============================================================================
// IMAGE PROCESSING UTILITIES
// ============================================================================

/**
 * Get or create a canvas from the pool
 */
function getCanvas(width: number, height: number): HTMLCanvasElement {
  const canvas = canvasPool.pop() || document.createElement('canvas')
  canvas.width = width
  canvas.height = height
  return canvas
}

/**
 * Return canvas to the pool
 */
function releaseCanvas(canvas: HTMLCanvasElement): void {
  if (canvasPool.length < 5) {
    canvasPool.push(canvas)
  }
}

/**
 * Load image from File/Blob/HTMLImageElement
 */
async function loadImage(input: File | Blob | HTMLImageElement): Promise<HTMLImageElement> {
  if (input instanceof HTMLImageElement) {
    return input
  }
  
  return new Promise((resolve, reject) => {
    const img = new Image()
    img.crossOrigin = 'anonymous'
    
    img.onload = () => resolve(img)
    img.onerror = () => reject(new Error('Failed to load image'))
    
    if (input instanceof File || input instanceof Blob) {
      img.src = URL.createObjectURL(input)
    }
  })
}

/**
 * Preprocess image for RMBG-1.4 inference
 * - Resize to INPUT_SIZE x INPUT_SIZE
 * - Convert to float32 CHW format (1x3xHxW)
 * - Normalize with mean/std
 */
async function preprocessImage(
  image: HTMLImageElement,
  ort: typeof ORT
): Promise<ORT.Tensor> {
  const { INPUT_SIZE, MEAN, STD } = CONFIG

  // Create canvas and resize image
  const canvas = getCanvas(INPUT_SIZE, INPUT_SIZE)
  const ctx = canvas.getContext('2d')!

  // Draw image with HIGH quality for better edge detection and accuracy
  // This is critical for preserving foreground details
  ctx.imageSmoothingEnabled = true
  ctx.imageSmoothingQuality = 'high' // High quality for better segmentation
  ctx.drawImage(image, 0, 0, INPUT_SIZE, INPUT_SIZE)

  // Get pixel data
  const imageData = ctx.getImageData(0, 0, INPUT_SIZE, INPUT_SIZE)
  const { data } = imageData

  releaseCanvas(canvas)

  // Convert to CHW format and normalize
  const inputSize = 3 * INPUT_SIZE * INPUT_SIZE
  const inputData = new Float32Array(inputSize)

  for (let i = 0; i < INPUT_SIZE * INPUT_SIZE; i++) {
    const r = data[i * 4] / 255.0
    const g = data[i * 4 + 1] / 255.0
    const b = data[i * 4 + 2] / 255.0

    // CHW format: [C, H, W]
    inputData[i] = (r - MEAN[0]) / STD[0]  // R channel
    inputData[INPUT_SIZE * INPUT_SIZE + i] = (g - MEAN[1]) / STD[1]  // G channel
    inputData[INPUT_SIZE * INPUT_SIZE * 2 + i] = (b - MEAN[2]) / STD[2]  // B channel
  }

  return new ort.Tensor('float32', inputData, [1, 3, INPUT_SIZE, INPUT_SIZE])
}

/**
 * Apply Gaussian blur to smooth alpha mask edges
 * This helps reduce jagged edges and improves edge quality
 */
function smoothAlphaMask(data: Uint8ClampedArray, width: number, height: number, radius: number = 1): void {
  const tempData = new Uint8ClampedArray(data)
  const kernel: number[] = []

  // Generate Gaussian kernel
  let sum = 0
  for (let i = -radius; i <= radius; i++) {
    const value = Math.exp(-(i * i) / (2 * radius * radius))
    kernel.push(value)
    sum += value
  }

  // Normalize kernel
  for (let i = 0; i < kernel.length; i++) {
    kernel[i] /= sum
  }

  // Horizontal pass
  for (let y = 0; y < height; y++) {
    for (let x = 0; x < width; x++) {
      let value = 0
      for (let k = -radius; k <= radius; k++) {
        const px = Math.max(0, Math.min(width - 1, x + k))
        const idx = (y * width + px) * 4
        value += tempData[idx] * kernel[k + radius]
      }
      const idx = (y * width + x) * 4
      data[idx] = data[idx + 1] = data[idx + 2] = Math.round(value)
    }
  }

  // Vertical pass
  tempData.set(data)
  for (let y = 0; y < height; y++) {
    for (let x = 0; x < width; x++) {
      let value = 0
      for (let k = -radius; k <= radius; k++) {
        const py = Math.max(0, Math.min(height - 1, y + k))
        const idx = (py * width + x) * 4
        value += tempData[idx] * kernel[k + radius]
      }
      const idx = (y * width + x) * 4
      data[idx] = data[idx + 1] = data[idx + 2] = Math.round(value)
    }
  }
}

/**
 * Enhance alpha mask contrast - CONSERVATIVE VERSION
 * Only suppresses very low alpha values (clear background)
 * Preserves all potential foreground pixels to avoid cutting subject
 */
function enhanceAlphaMask(data: Uint8ClampedArray, width: number, height: number): void {
  // Very conservative enhancement - only clean up obvious background
  // DO NOT touch potential foreground pixels

  for (let i = 0; i < width * height; i++) {
    const idx = i * 4
    let alpha = data[idx] / 255.0

    // Only suppress very low alpha values (< 0.1 = definitely background)
    // Leave everything else untouched to preserve foreground
    if (alpha < 0.1) {
      alpha = alpha * 0.5 // Suppress clear background
    } else if (alpha > 0.9) {
      alpha = Math.min(1.0, alpha * 1.05) // Slightly boost clear foreground
    }
    // Everything in between (0.1 - 0.9) is left UNCHANGED to preserve edges and foreground

    // Clamp and convert back
    alpha = Math.max(0, Math.min(1, alpha))
    const value = Math.round(alpha * 255)

    data[idx] = data[idx + 1] = data[idx + 2] = value
  }
}

/**
 * Postprocess model output to create alpha mask
 * - Extract alpha values from output tensor
 * - Enhance and smooth alpha mask for better edges
 * - Resize to original image dimensions
 * - Apply to original image to create RGBA
 */
async function postprocessOutput(
  output: ORT.Tensor,
  originalImage: HTMLImageElement,
  outputFormat: 'image/png' | 'image/webp'
): Promise<Blob> {
  const { INPUT_SIZE } = CONFIG
  const { width: origWidth, height: origHeight } = originalImage

  // Extract alpha mask from output tensor
  const outputData = output.data as Float32Array

  // Create canvas for alpha mask at model resolution
  const maskCanvas = getCanvas(INPUT_SIZE, INPUT_SIZE)
  const maskCtx = maskCanvas.getContext('2d')!
  const maskImageData = maskCtx.createImageData(INPUT_SIZE, INPUT_SIZE)

  // Convert float mask to grayscale image data with better precision
  let minAlpha = 1.0, maxAlpha = 0.0, sumAlpha = 0.0

  for (let i = 0; i < INPUT_SIZE * INPUT_SIZE; i++) {
    // Use full precision without aggressive clamping
    const alpha = Math.max(0, Math.min(1, outputData[i]))
    const value = Math.round(alpha * 255)

    // Track statistics for debugging
    if (CONFIG.LOG_ALPHA_STATS) {
      minAlpha = Math.min(minAlpha, alpha)
      maxAlpha = Math.max(maxAlpha, alpha)
      sumAlpha += alpha
    }

    maskImageData.data[i * 4] = value      // R
    maskImageData.data[i * 4 + 1] = value  // G
    maskImageData.data[i * 4 + 2] = value  // B
    maskImageData.data[i * 4 + 3] = 255    // A
  }

  // Log alpha mask statistics
  if (CONFIG.LOG_ALPHA_STATS) {
    const avgAlpha = sumAlpha / (INPUT_SIZE * INPUT_SIZE)
    console.log(`üìä Alpha Mask Stats (Raw Model Output):`)
    console.log(`   Min: ${minAlpha.toFixed(3)}, Max: ${maxAlpha.toFixed(3)}, Avg: ${avgAlpha.toFixed(3)}`)
  }

  // Apply edge smoothing if enabled (reduces jagged edges)
  if (CONFIG.ENABLE_SMOOTHING) {
    smoothAlphaMask(maskImageData.data, INPUT_SIZE, INPUT_SIZE, CONFIG.SMOOTHING_RADIUS)
  }

  // Apply conservative enhancement if enabled (only cleans obvious background)
  // DISABLED by default to preserve foreground and avoid cutting subject
  if (CONFIG.ENABLE_ENHANCEMENT) {
    enhanceAlphaMask(maskImageData.data, INPUT_SIZE, INPUT_SIZE)
  }

  maskCtx.putImageData(maskImageData, 0, 0)

  // Create final output canvas at original resolution
  const outputCanvas = getCanvas(origWidth, origHeight)
  const outputCtx = outputCanvas.getContext('2d')!

  // Draw original image
  outputCtx.drawImage(originalImage, 0, 0, origWidth, origHeight)

  // Get original image data
  const originalImageData = outputCtx.getImageData(0, 0, origWidth, origHeight)

  // Resize mask to original dimensions with HIGH quality for better edges
  const resizedMaskCanvas = getCanvas(origWidth, origHeight)
  const resizedMaskCtx = resizedMaskCanvas.getContext('2d')!
  resizedMaskCtx.imageSmoothingEnabled = true
  resizedMaskCtx.imageSmoothingQuality = 'high' // High quality for smooth edges
  resizedMaskCtx.drawImage(maskCanvas, 0, 0, origWidth, origHeight)

  const resizedMaskData = resizedMaskCtx.getImageData(0, 0, origWidth, origHeight)

  // Apply alpha mask to original image directly
  // No second smoothing pass or gamma correction to preserve model output and improve speed
  for (let i = 0; i < origWidth * origHeight; i++) {
    const alpha = resizedMaskData.data[i * 4] / 255.0
    originalImageData.data[i * 4 + 3] = Math.round(alpha * 255)
  }

  // Put final image data
  outputCtx.putImageData(originalImageData, 0, 0)

  // Clean up
  releaseCanvas(maskCanvas)
  releaseCanvas(resizedMaskCanvas)

  // Yield to browser before blob conversion
  await new Promise(resolve => requestAnimationFrame(() => resolve(undefined)))

  // Convert to blob
  return new Promise((resolve, reject) => {
    outputCanvas.toBlob(
      (blob) => {
        releaseCanvas(outputCanvas)
        if (blob) {
          resolve(blob)
        } else {
          reject(new Error('Failed to create output blob'))
        }
      },
      outputFormat,
      0.95
    )
  })
}

// ============================================================================
// MAIN API
// ============================================================================

/**
 * Remove background from image using RMBG-1.4 ONNX model
 *
 * @param input - Image as File, Blob, or HTMLImageElement
 * @param options - Configuration options
 * @returns Result with blob, dataUrl, and metadata
 *
 * @example
 * ```typescript
 * const result = await removeBackground(imageFile, {
 *   quality: 'balanced',
 *   onProgress: (progress, stage) => console.log(`${stage}: ${progress}%`)
 * })
 *
 * // Use the result
 * const img = document.createElement('img')
 * img.src = result.dataUrl
 * ```
 */
export async function removeBackground(
  input: File | Blob | HTMLImageElement,
  options: RemoveBackgroundOptions = {}
): Promise<RemoveBackgroundResult> {
  const {
    outputFormat = 'image/png',
    onProgress,
  } = options

  const startTime = performance.now()

  // Log configuration if debug enabled
  if (CONFIG.DEBUG_LOGGING) {
    console.log('‚öôÔ∏è  RMBG-1.4 Configuration:')
    console.log(`   Model: RMBG-1.4 (State-of-the-art background removal)`)
    console.log(`   Resolution: ${CONFIG.INPUT_SIZE}x${CONFIG.INPUT_SIZE}`)
    console.log(`   Normalization: MEAN=[${CONFIG.MEAN.join(', ')}], STD=[${CONFIG.STD.join(', ')}]`)
    console.log(`   Smoothing: ${CONFIG.ENABLE_SMOOTHING ? `Enabled (radius=${CONFIG.SMOOTHING_RADIUS})` : 'Disabled'}`)
    console.log(`   Enhancement: ${CONFIG.ENABLE_ENHANCEMENT ? 'Enabled' : 'Disabled (preserves foreground)'}`)
  }

  // Try @imgly/background-removal first (most reliable for browser)
  console.log('üîÑ Attempting @imgly/background-removal (browser-optimized)...')
  console.log('‚ÑπÔ∏è  Note: ONNX Runtime threading warnings from @imgly are harmless and can be ignored')
  let imglyError: any = null
  try {
    const { removeBackground: imglyRemoveBackground } = await import('@imgly/background-removal')

    onProgress?.(10, 'Loading @imgly model')

    const blob = await imglyRemoveBackground(input, {
      debug: false,
      proxyToWorker: true, // Use Web Worker for better performance
      device: 'cpu', // Use CPU to avoid WebGPU issues
      model: 'isnet_quint8', // Use quantized model for faster processing
      progress: (key, current, total) => {
        const progress = Math.round((current / total) * 100)
        onProgress?.(10 + Math.round(progress * 0.8), `Processing: ${key}`)
      },
      output: {
        format: outputFormat as 'image/png' | 'image/jpeg' | 'image/webp',
        quality: 0.9,
      },
    })

    const dataUrl = URL.createObjectURL(blob)
    const processingTime = performance.now() - startTime

    onProgress?.(100, 'Complete')
    console.log(`‚úÖ Background removed with @imgly in ${processingTime.toFixed(0)}ms`)

    return {
      blob,
      dataUrl,
      width: 0, // @imgly doesn't provide dimensions
      height: 0,
      processingTime,
      executionProvider: 'imgly' as const,
    }
  } catch (error) {
    imglyError = error
    console.warn('‚ö†Ô∏è  @imgly/background-removal failed:', error)
  }

  // Try RMBG-1.4 ONNX Runtime as fallback
  console.log('üîÑ Attempting RMBG-1.4 ONNX Runtime (state-of-the-art model)...')
  let rmbgError: any = null
  try {
    // Initialize with progress tracking (handles model download/caching)
    await initialize((progress, stage) => {
      // Map initialization progress to 5-50% range
      const mappedProgress = 5 + Math.round(progress * 0.45)
      onProgress?.(mappedProgress, stage)
    })

    if (!ortInstance || !inferenceSession) {
      throw new Error('ONNX Runtime not initialized')
    }

    // Load image
    onProgress?.(55, 'Loading image')
    const image = await loadImage(input)
    const { width, height } = image

    onProgress?.(60, 'Image loaded')

    // Preprocess
    const inputTensor = await preprocessImage(image, ortInstance)

    onProgress?.(70, 'Preprocessing complete')

    // Run inference
    onProgress?.(75, 'Running AI model')

    const inputName = inferenceSession.inputNames[0] || CONFIG.INPUT_NAME
    const outputName = inferenceSession.outputNames[0] || CONFIG.OUTPUT_NAME

    const feeds = { [inputName]: inputTensor }
    const results = await inferenceSession.run(feeds)
    const outputTensor = results[outputName]

    onProgress?.(85, 'AI processing complete')

    // Postprocess
    onProgress?.(90, 'Creating final image')

    const blob = await postprocessOutput(outputTensor, image, outputFormat)

    // Create data URL
    onProgress?.(95, 'Finalizing')

    const dataUrl = URL.createObjectURL(blob)

    const processingTime = performance.now() - startTime

    onProgress?.(100, 'Complete')

    console.log(`‚úÖ Background removed with RMBG-1.4 in ${processingTime.toFixed(0)}ms`)

    // Determine execution provider
    const executionProvider = isWebGPUAvailable() ? 'webgpu' : 'wasm'

    return {
      blob,
      dataUrl,
      processingTime,
      executionProvider,
      width,
      height,
    }
  } catch (error) {
    rmbgError = error
    console.error('‚ùå RMBG-1.4 failed:', error)
  }

  // Last resort: try server fallback
  console.log('üîÑ Attempting server fallback...')
  try {
    return await removeBackgroundServer(input, outputFormat, onProgress)
  } catch (serverError) {
    console.error('‚ùå Server fallback also failed:', serverError)
    throw new Error(
      `Background removal failed. ` +
      `@imgly error: ${imglyError}. ` +
      `RMBG-1.4 error: ${rmbgError}. ` +
      `Server error: ${serverError}`
    )
  }
}

/**
 * Server fallback implementation
 */
async function removeBackgroundServer(
  input: File | Blob | HTMLImageElement,
  outputFormat: 'image/png' | 'image/webp',
  onProgress?: (progress: number, stage: string) => void
): Promise<RemoveBackgroundResult> {
  const startTime = performance.now()

  try {
    onProgress?.(10, 'Uploading to server')

    // Convert input to blob
    let blob: Blob
    if (input instanceof HTMLImageElement) {
      const canvas = getCanvas(input.width, input.height)
      const ctx = canvas.getContext('2d')!
      ctx.drawImage(input, 0, 0)
      blob = await new Promise<Blob>((resolve, reject) => {
        canvas.toBlob(
          (b) => (b ? resolve(b) : reject(new Error('Failed to create blob'))),
          'image/png'
        )
      })
      releaseCanvas(canvas)
    } else {
      blob = input
    }

    // Create form data
    const formData = new FormData()
    formData.append('image', blob, 'image.png')
    formData.append('format', outputFormat)

    // Send to server
    onProgress?.(30, 'Processing on server')
    const response = await fetch(CONFIG.SERVER_ENDPOINT, {
      method: 'POST',
      body: formData,
    })

    if (!response.ok) {
      throw new Error(`Server returned ${response.status}: ${response.statusText}`)
    }

    onProgress?.(80, 'Receiving result')
    const resultBlob = await response.blob()
    const dataUrl = URL.createObjectURL(resultBlob)

    // Get dimensions from response headers or blob
    const width = parseInt(response.headers.get('X-Image-Width') || '0', 10)
    const height = parseInt(response.headers.get('X-Image-Height') || '0', 10)

    const processingTime = performance.now() - startTime

    onProgress?.(100, 'Complete')

    console.log(`‚úÖ Background removed via server in ${processingTime.toFixed(0)}ms`)

    return {
      blob: resultBlob,
      dataUrl,
      processingTime,
      executionProvider: 'server',
      width,
      height,
    }
  } catch (error) {
    console.error('‚ùå Server fallback failed:', error)
    throw new Error(`Server fallback failed: ${error}`)
  }
}

// ============================================================================
// UTILITY FUNCTIONS
// ============================================================================

/**
 * Check if background removal is supported in current environment
 */
export function isSupported(): boolean {
  return typeof window !== 'undefined' && typeof document !== 'undefined'
}

/**
 * Get information about available execution providers
 */
export async function getExecutionProviderInfo(): Promise<{
  webgpu: boolean
  wasm: boolean
  recommended: 'webgpu' | 'wasm'
}> {
  const webgpu = isWebGPUAvailable()
  const wasm = true // WASM is always available in modern browsers

  return {
    webgpu,
    wasm,
    recommended: webgpu ? 'webgpu' : 'wasm',
  }
}

/**
 * Reset the module (clear session, release resources)
 */
export function reset(): void {
  inferenceSession = null
  isInitialized = false
  initializationPromise = null
  canvasPool.length = 0
  console.log('üîÑ RMBG-1.4 module reset')
}


